import streamlit as st
import os
import tempfile

from utils.audio_utils import extract_loudness_peaks
from utils.transcript_utils import (
    transcribe_video,
    get_relevant_segments
)
from utils.gemini_utils import rank_segments_with_gemini
from utils.video_utils import generate_reels


# -------------------------------------------------
# Streamlit page config
# -------------------------------------------------
st.set_page_config(
    page_title="ByteSize â€“ Automatic Reel Generator",
    layout="centered"
)

st.title("ğŸ¬ ByteSize â€“ Automatic Reel Generator")
st.markdown(
    """
    Upload a **long-form video** (lecture, interview, podcast) and automatically
    generate **high-impact short reels** using **multimodal AI**:

    - ğŸ”Š Audio loudness (emotion / emphasis)
    - ğŸ§  Speech understanding (Whisper)
    - ğŸ¤– Semantic reasoning (Gemini)
    - ğŸ¥ Automatic reel generation
    - ğŸ“± Reels/TikTok-ready vertical videos
    - ğŸ“ Timed captions
    """
)

# -------------------------------------------------
# Video upload
# -------------------------------------------------
uploaded_file = st.file_uploader(
    "Upload a video file",
    type=["mp4", "mov", "mkv"]
)

if uploaded_file:
    with tempfile.TemporaryDirectory() as tmpdir:
        video_path = os.path.join(tmpdir, uploaded_file.name)

        with open(video_path, "wb") as f:
            f.write(uploaded_file.read())

        st.success("âœ… Video uploaded successfully!")

        if st.button("ğŸš€ Generate Reels"):
            with st.spinner("Processing video (this may take a few minutes)..."):

                # -------------------------------------------------
                # Phase 1: Audio loudness
                # -------------------------------------------------
                st.write("ğŸ”Š Detecting loudness peaks...")
                peaks = extract_loudness_peaks(video_path, top_k=5)

                if not peaks:
                    st.warning("âš ï¸ No loudness peaks detected.")
                    st.stop()

                # -------------------------------------------------
                # Phase 2: Transcription
                # -------------------------------------------------
                st.write("ğŸ§  Transcribing video with Whisper...")
                segments = transcribe_video(video_path, model_size="base")

                if not segments:
                    st.warning("âš ï¸ Transcription failed.")
                    st.stop()

                # -------------------------------------------------
                # Phase 3: Heuristic multimodal fusion
                # -------------------------------------------------
                st.write("ğŸ”— Matching loudness with meaningful speech...")
                candidate_segments = get_relevant_segments(
                    segments=segments,
                    peaks=peaks,
                    window=15,
                    min_words=6
                )

                if not candidate_segments:
                    st.warning("âš ï¸ No high-value moments detected.")
                    st.stop()

                # -------------------------------------------------
                # Phase 4: Gemini semantic refinement
                # -------------------------------------------------
                st.write("ğŸ¤– Refining highlights with Gemini 2.5 Flash...")
                refined_segments = rank_segments_with_gemini(
                    candidate_segments,
                    top_k=5
                )

                if not refined_segments:
                    st.warning("âš ï¸ Gemini returned no usable segments.")
                    st.stop()

                # -------------------------------------------------
                # Phase 5: Reel generation (Dynamic 40â€“100s)
                # -------------------------------------------------
                st.write("ğŸ¬ Generating reels (dynamic 40â€“100s)...")
                reels = generate_reels(
                    video_path=video_path,
                    segments=refined_segments,
                    transcript_segments=segments,
                    output_dir="output/clips"
                )

                if not reels:
                    st.warning("âš ï¸ Reel generation failed.")
                    st.stop()

                st.success("ğŸ‰ Reels generated successfully!")

                # -------------------------------------------------
                # Display results
                # -------------------------------------------------
                st.subheader("ğŸ“‚ Generated Reels")

                for i, reel in enumerate(reels, 1):
                    st.markdown(f"## Reel {i}")

                    st.markdown("### ğŸ¥ Horizontal (16:9)")
                    st.video(reel["horizontal"])

                    st.markdown("### ğŸ“± Vertical (9:16)")
                    st.video(reel["vertical"])

                    st.markdown("### ğŸ“ Vertical with Captions")
                    st.video(reel["captioned"])
                    st.markdown("---")